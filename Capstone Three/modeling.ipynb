{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d666bbc9",
   "metadata": {},
   "source": [
    "## Preprocessing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b217921",
   "metadata": {},
   "source": [
    "Recall that the data we are working with are complaints filed to the Consumer Financial Protection Bureau in 2022. Our target variable is predicting 'Timely response?'. We will need to perform NLP on 'Consumer complaint narrative'. Our top catagorical features based on chi-square analysis are 'Product', 'Sub-product', 'Company', which are self explanatory features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4c0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434a575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the previous notebook, we dropped irrelevant columns\n",
    "df = pd.read_csv('complaints-2024-07-16_13_58.csv')\n",
    "columns_to_drop=['Date received','Company public response','State','ZIP code','Tags','Consumer consent provided?','Submitted via','Date sent to company','Company response to consumer','Consumer disputed?','Complaint ID']\n",
    "df = df.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768bcc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product', 'Sub-product', 'Issue', 'Sub-issue',\n",
       "       'Consumer complaint narrative', 'Company', 'Timely response?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da49ea",
   "metadata": {},
   "source": [
    "Let us first start with a rudimentary decision tree model that just uses the features 'Company' and 'Consumer complaint narrative' to predict 'Timely response?'.\n",
    "\n",
    "For the features we need:\n",
    "- to handle the redacted text in consumer complaints. I opted at first to replace the X's with '\\<REDACTED>'. Later the X's will be removed.\n",
    "- use an encoder for the companies, I opted for ordinal because 2k+ unique companies seemed like too much for one-hot encoding\n",
    "\n",
    "We will look at the classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea08823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5478\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "features = df.drop(['Timely response?'],axis=1)\n",
    "target = df['Timely response?'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Function to handle redacted information\n",
    "def handle_redacted(text, strategy=\"replace\"):\n",
    "    if strategy == \"replace\":\n",
    "        return re.sub(r'XX+', '<REDACTED>', text)\n",
    "    elif strategy == \"remove\":\n",
    "        return re.sub(r'XX+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply the redacted handling function\n",
    "features['Consumer complaint narrative'] = features['Consumer complaint narrative'].apply(lambda x: handle_redacted(x, strategy=\"replace\"))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization for complaint narratives\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['Consumer complaint narrative'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['Consumer complaint narrative'])\n",
    "\n",
    "# Ordinal Encoding for companies\n",
    "# Combine training and testing data for encoding\n",
    "combined_data = pd.concat([X_train[['Company']], X_test[['Company']]])\n",
    "\n",
    "# Initialize OrdinalEncoder with handle_unknown='use_encoded_value' (optional)\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit and transform on combined data\n",
    "combined_encoded = ordinal_encoder.fit_transform(combined_data)\n",
    "\n",
    "# Split back into training and testing sets\n",
    "X_train_companies_encoded = combined_encoded[:len(X_train)]\n",
    "X_test_companies_encoded = combined_encoded[len(X_train):]\n",
    "\n",
    "# Combine TF-IDF vectors and company encodings\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_companies_encoded.reshape(-1, 1)])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_companies_encoded.reshape(-1, 1)])\n",
    "# Combine TF-IDF vectors and company encodings\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_companies_encoded])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_companies_encoded])\n",
    "\n",
    "# Train the Decision Tree model\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict_proba(X_test_combined)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6da347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.10      0.10       533\n",
      "           1       0.99      0.99      0.99     65110\n",
      "\n",
      "    accuracy                           0.99     65643\n",
      "   macro avg       0.55      0.55      0.55     65643\n",
      "weighted avg       0.99      0.99      0.99     65643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c4bed",
   "metadata": {},
   "source": [
    "Although the accuracy is around 99%, recall that our data is imbalanced and that around 2% of our data is negative. So accuracy is not a good metric for our models. Instead we will look at AUC. Let's compare with two other models: Random Forest and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a107f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7728\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "features = df.drop(['Timely response?'],axis=1)\n",
    "target = df['Timely response?'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Function to handle redacted information\n",
    "def handle_redacted(text, strategy=\"replace\"):\n",
    "    if strategy == \"replace\":\n",
    "        return re.sub(r'XX+', '<REDACTED>', text)\n",
    "    elif strategy == \"remove\":\n",
    "        return re.sub(r'XX+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply the redacted handling function\n",
    "features['Consumer complaint narrative'] = features['Consumer complaint narrative'].apply(lambda x: handle_redacted(x, strategy=\"replace\"))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization for complaint narratives\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['Consumer complaint narrative'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['Consumer complaint narrative'])\n",
    "\n",
    "# Ordinal Encoding for companies\n",
    "# Combine training and testing data for encoding\n",
    "combined_data = pd.concat([X_train[['Company']], X_test[['Company']]])\n",
    "\n",
    "# Initialize OrdinalEncoder with handle_unknown='use_encoded_value' (optional)\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit and transform on combined data\n",
    "combined_encoded = ordinal_encoder.fit_transform(combined_data)\n",
    "\n",
    "# Split back into training and testing sets\n",
    "X_train_companies_encoded = combined_encoded[:len(X_train)]\n",
    "X_test_companies_encoded = combined_encoded[len(X_train):]\n",
    "\n",
    "# Combine TF-IDF vectors and company encodings\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_companies_encoded.reshape(-1, 1)])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_companies_encoded.reshape(-1, 1)])\n",
    "# Combine TF-IDF vectors and company encodings\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_companies_encoded])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_companies_encoded])\n",
    "\n",
    "# Train the Decision Tree model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict_proba(X_test_combined)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942e2a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Whyme\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "features = df.drop(['Timely response?'],axis=1)\n",
    "target = df['Timely response?'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Function to handle redacted information\n",
    "def handle_redacted(text, strategy=\"replace\"):\n",
    "    if strategy == \"replace\":\n",
    "        return re.sub(r'XX+', '<REDACTED>', text)\n",
    "    elif strategy == \"remove\":\n",
    "        return re.sub(r'XX+', '', text)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply the redacted handling function\n",
    "features['Consumer complaint narrative'] = features['Consumer complaint narrative'].apply(lambda x: handle_redacted(x, strategy=\"replace\"))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF Vectorization for complaint narratives\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['Consumer complaint narrative'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['Consumer complaint narrative'])\n",
    "\n",
    "# Ordinal Encoding for companies\n",
    "# Combine training and testing data for encoding\n",
    "combined_data = pd.concat([X_train[['Company']], X_test[['Company']]])\n",
    "\n",
    "# Initialize OrdinalEncoder with handle_unknown='use_encoded_value' (optional)\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit and transform on combined data\n",
    "combined_encoded = ordinal_encoder.fit_transform(combined_data)\n",
    "\n",
    "# Split back into training and testing sets\n",
    "X_train_companies_encoded = combined_encoded[:len(X_train)]\n",
    "X_test_companies_encoded = combined_encoded[len(X_train):]\n",
    "\n",
    "# Combine TF-IDF vectors and company encodings\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_companies_encoded.reshape(-1, 1)])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_companies_encoded.reshape(-1, 1)])\n",
    "# Combine TF-IDF vectors and company encodings\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_companies_encoded])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_companies_encoded])\n",
    "\n",
    "# Train the Decision Tree model\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict_proba(X_test_combined)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb4896",
   "metadata": {},
   "source": [
    "So far the AUC scores are:\n",
    "- DecisionTreeClassifier: 0.5478\n",
    "- RandomForestClassifier: 0.7728\n",
    "- LogisticRegression: 0.7997\n",
    "\n",
    "Default Logistic Regression seems to provide the best results and the decision tree is the worst, so we will Logistic Regression compare with Random Forest from now on.\n",
    "\n",
    "For the following models, I implemented the following changes:\n",
    "- features are now\n",
    "    - 'Company': ordinal encoding\n",
    "    - 'Product': ordinal encoding\n",
    "    - 'Sub-product': ordinal encoding, drop the 4 null rows\n",
    "    - 'Consumer complaint narrative': remove X's and handle dates. Then use TfidfVectorizer.\n",
    "- models will have the parameter <code>class_weight='balanced'</code> to ensure the imbalanced data is accounted for\n",
    "- pipelines will be implemented for person ease of use\n",
    "    - a grid search of hyperparameters will be attempted with Logistic regression as well as undersampling, but the default parameters will also be noted in case the model complexity is detrimental to new unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1814e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Whyme\\AppData\\Local\\Temp\\ipykernel_33944\\265405519.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features['Sub-product'] = features['Sub-product'].fillna('Unknown')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC: 0.8469\n",
      "Best parameters: {'logisticregression__C': 1.0, 'logisticregression__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Function to handle redacted information\n",
    "def handle_redacted(text, strategy=\"replace\"):\n",
    "    if not isinstance(text, str):\n",
    "        return text  # Return as is if not a string\n",
    "    if strategy == \"replace\":\n",
    "        text = re.sub(r'XX+', '<REDACTED>', text)\n",
    "    elif strategy == \"remove\":\n",
    "        text = re.sub(r'XX+', '', text)\n",
    "    # Handle dates\n",
    "    text = re.sub(r'\\b\\d{2}/\\d{2}/\\d{4}\\b', '<DATE>', text)\n",
    "    return text\n",
    "\n",
    "# Custom transformer for handling redacted and sensitive information\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy=\"replace\"):\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda text: handle_redacted(text, self.strategy))\n",
    "\n",
    "# Select relevant columns\n",
    "features = df[['Company', 'Product' ,'Sub-product', 'Consumer complaint narrative']]\n",
    "target = df['Timely response?'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "features['Sub-product'] = features['Sub-product'].fillna('Unknown')\n",
    "\n",
    "# Define text preprocessing pipeline\n",
    "text_pipeline = Pipeline([\n",
    "    ('redacted_handling', TextPreprocessor(strategy=\"remove\")),\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=5000))\n",
    "])\n",
    "\n",
    "# Define column transformer for categorical features\n",
    "categorical_features = ['Company', 'Product' ,'Sub-product']\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Combine text and categorical features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('text', text_pipeline, 'Consumer complaint narrative'),\n",
    "    ('categorical', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Define the full pipeline with undersampling\n",
    "pipeline_lr = make_pipeline(\n",
    "    preprocessor,\n",
    "    RandomUnderSampler(random_state=42),\n",
    "    LogisticRegression(random_state=42, class_weight='balanced', max_iter=100000)\n",
    ")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.1, 1.0, 10.0],\n",
    "    'logisticregression__solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_lr = GridSearchCV(pipeline_lr, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict with Logistic Regression\n",
    "y_pred_lr = grid_search_lr.predict_proba(X_test)[:, 1]\n",
    "auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression AUC: {auc_lr:.4f}\")\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best parameters: {grid_search_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d290fc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC: 0.8524\n"
     ]
    }
   ],
   "source": [
    "# Update pipeline to use Logistic Regression\n",
    "pipeline_lr = make_pipeline(preprocessor, LogisticRegression(random_state=42, class_weight='balanced', max_iter=100000))\n",
    "\n",
    "# Train the Logistic Regression pipeline\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict with Logistic Regression\n",
    "y_pred_lr = pipeline_lr.predict_proba(X_test)[:, 1]\n",
    "auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression AUC: {auc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f4799ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUC: 0.8083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Update pipeline to use Random Forest\n",
    "pipeline_rf = make_pipeline(preprocessor, RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "\n",
    "# Train the Random Forest pipeline\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict with Random Forest\n",
    "y_pred_rf = pipeline_rf.predict_proba(X_test)[:, 1]\n",
    "auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest AUC: {auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077e8e5",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97b86a",
   "metadata": {},
   "source": [
    "The AUC score are summarized:\n",
    "\n",
    "| model (class_weight='balanced')                         | AUC    |\n",
    "|---------------------------------------------------------|--------|\n",
    "| Logistic Regression with grid search and under sampling | 0.8469 |\n",
    "| Logistic Regression                                     | 0.8524 |\n",
    "| Random Forest                                           | 0.8083 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92597d",
   "metadata": {},
   "source": [
    "Recall that the Area Under the ROC curve is a value between 0 and 1 that summarizes the ROC curve (plot of the true positive rate against the false positive rate), where 0.5 AUC represents a model that is random.\n",
    "\n",
    "Logistic Regression seems to be the best performing modeling. We would need to balance having a complex model which has the chance to overfit and using the simpler model which may not capture all important features. Here it seems that the simple Logistic Regression model with default parameters (aside from balanced class weight) is the best choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c033aa2",
   "metadata": {},
   "source": [
    "## Further Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19ed7fd",
   "metadata": {},
   "source": [
    "For more advanced language models, the narratives can be broken down into more keyboards that extract phrases that indicate urgency, complexity, emotional tone, and specific requests. This requires more specific words that can be registered for their frequency.\n",
    "\n",
    "The models can be applied to more years in the range of complaints to the Consumer Financial Protection Bureau. Complaints with narratives only account for 42% of all complaints in 2022, so we may want to consider the remaining data. This would point to particular companies or products that are more likely to have untimely responses, although this may not require machine learning as NLP is not required for 58% of the data. \n",
    "\n",
    "Outside this dataset, we can look at whether or not the dates could be related to why some companies did not offer a timely response. Perhaps some companies were going through bankruptcy and so did not have consumer complaints as a priority. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
